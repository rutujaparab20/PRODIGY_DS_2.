# PRODIGY_DS_2.
üîç Data Preprocessing ‚Äì Task 2 Complete! Proud to complete the second task of my Data Science internship with Prodigy Infotech. Learned how to transform raw data into clean, structured formats for better analysis and modeling. This step is crucial before feeding data into any machine learning model.
<br>
<img src="https://github.com/rutujaparab20/PRODIGY_DS_2./blob/main/ds_task_2.png">

## Objective
In this task, I performed data preprocessing techniques which are crucial before applying any machine learning algorithms. This includes handling missing values, encoding, normalization, and cleaning the dataset to make it suitable for analysis or modeling.

## Dataset 
A structured CSV file is used <a href="https://github.com/rutujaparab20/PRODIGY_DS_2./blob/main/test.csv">test </a> to demonstrate essential data preprocessing steps like handling missing values, normalization, and encoding.


## Technologies Used

- Python
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Jupyter Notebook

## Key Steps Taken

- Handled null values
- Removed duplicate entries
- Normalized data
- Visualized distribution and correlation
- Encoded categorical values (if any)

## Conclusion

Through this task, I explored key data preprocessing techniques that are crucial before any data analysis or machine learning. Handling missing values, normalizing data, and encoding features help make the dataset consistent, reliable, and suitable for building effective models.



